{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pybalu.feature_extraction import lbp_features\n",
    "from pybalu.performance_eval import performance\n",
    "from pybalu.feature_selection import clean, sfs\n",
    "from pybalu.io import imread\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressBar(value, endvalue, bar_length=20):\n",
    "    \n",
    "    # Visaulización obtenida de https://stackoverflow.com/questions/6169217/replace-console-output-in-python\n",
    "    \n",
    "    percent = float(value) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "\n",
    "    sys.stdout.write(\"\\rPercent: [{0}] {1}%\".format(arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Elegimos $hdiv = 2$ y $vdiv = 2$ dado que entregan buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiv, vdiv = 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: [------------------->] 100%\n",
      "LBPs Calculado\n",
      "LBP Shape: 350, 1024\n",
      "IDs Shape: 350, 1\n"
     ]
    }
   ],
   "source": [
    "directory = 'faces_ARLQ'\n",
    "\n",
    "LBPs = []\n",
    "IDs = []\n",
    "NNs = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    \n",
    "    if filename.endswith(\".png\"):\n",
    "        \n",
    "        # Para un archivo \"face_xxx_nn.png\", ID es xxx y nn es nn, ambos en int\n",
    "        id_nn = filename[:-4].split(\"_\")\n",
    "        ID = int(id_nn[1])\n",
    "        nn = int(id_nn[2])\n",
    "                \n",
    "        if ID % 2 == 1: # Nos quedamos con los impares\n",
    "            if nn <= 7: # y solo los 7 primeros\n",
    "                i += 1\n",
    "        \n",
    "                # Leemos la imágen y obtenemos sus features dadas por lbp\n",
    "                im = imread(f\"{directory}/{filename}\")\n",
    "                lbp = lbp_features(im, hdiv=hdiv, vdiv=vdiv)\n",
    "                \n",
    "                # Guardamos los resultados\n",
    "                LBPs.append(lbp)\n",
    "                IDs.append(ID)\n",
    "                NNs.append(nn)\n",
    "                \n",
    "                if i % 10 == 0:                    \n",
    "                    progressBar(i, 350, bar_length=20)\n",
    "print(f\"\\nLBPs Calculado\\nLBP Shape: {len(LBPs)}, {len(LBPs[0])}\\nIDs Shape: {len(IDs)}, 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Antes de la selección de features, realizaremos un cleansing con Clean. Luego realizaremos SFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = [], [], [], []\n",
    "\n",
    "for lbp, ID, nn in zip(LBPs, IDs, NNs):\n",
    "    \n",
    "    # Como nos pide el enunciado, usamos las imágenes con nn=1 como testing, y el resto como training\n",
    "    \n",
    "    if nn == 1:\n",
    "        Xtest.append(lbp)\n",
    "        Ytest.append(ID)\n",
    "    else:\n",
    "        Xtrain.append(lbp)\n",
    "        Ytrain.append(ID)\n",
    "    \n",
    "# Transformamos a numpy arrays para que sea más fácil de trabajar (pybalu lo pide)\n",
    "Xtrain = np.array(Xtrain)\n",
    "Ytrain = np.array(Ytrain)\n",
    "Xtest = np.array(Xtest)\n",
    "Ytest = np.array(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned.\n",
      "Before:1024 features\n",
      "Now: 1024 features\n"
     ]
    }
   ],
   "source": [
    "before = len(Xtrain[0])\n",
    "\n",
    "# Realizamos la función clean previo a la selection de features mediante sfs, como se nos fue recomendados en clase \n",
    "p_clean = clean(Xtrain)\n",
    "\n",
    "after = len(p_clean)\n",
    "print(f\"Cleaned.\\nBefore:{before} features\\nNow: {after} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Después de obtener qué features usaremos, modificamos nuestro dataset a solo contener esas features\n",
    "\n",
    "Xtrain_cleaned = np.array([[x[i] for i in p_clean] for x in Xtrain])\n",
    "Xtest_cleaned = np.array([[x[i] for i in p_clean] for x in Xtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Un bug en el código de sfs no permite que los las clases se salten enteros (1,3,5,..)\n",
    "Modificamos esto solo para correr sfs\n",
    "\"\"\" \n",
    "\n",
    "Ytrain_sfs = np.array([int((y-1)/2) for y in Ytrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   0%|          | 0.00/100 [00:00<?, ? features/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   1%|          | 1.00/100 [00:03<05:30, 3.34s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   2%|▏         | 2.00/100 [00:07<05:43, 3.50s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   3%|▎         | 3.00/100 [00:11<05:59, 3.71s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   4%|▍         | 4.00/100 [00:15<06:05, 3.80s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   5%|▌         | 5.00/100 [00:19<06:11, 3.91s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   6%|▌         | 6.00/100 [00:24<06:30, 4.16s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   7%|▋         | 7.00/100 [00:28<06:39, 4.29s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   8%|▊         | 8.00/100 [00:33<06:49, 4.46s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:   9%|▉         | 9.00/100 [00:37<06:35, 4.34s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  10%|█         | 10.0/100 [00:42<06:28, 4.32s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  11%|█         | 11.0/100 [00:46<06:19, 4.27s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  12%|█▏        | 12.0/100 [00:50<06:14, 4.26s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  13%|█▎        | 13.0/100 [00:54<06:09, 4.25s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  14%|█▍        | 14.0/100 [00:59<06:06, 4.26s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  15%|█▌        | 15.0/100 [01:03<06:11, 4.37s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  16%|█▌        | 16.0/100 [01:07<05:58, 4.27s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  17%|█▋        | 17.0/100 [01:11<05:51, 4.24s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  18%|█▊        | 18.0/100 [01:16<05:55, 4.33s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  19%|█▉        | 19.0/100 [01:20<05:54, 4.38s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  20%|██        | 20.0/100 [01:25<05:45, 4.32s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  21%|██        | 21.0/100 [01:29<05:44, 4.37s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  22%|██▏       | 22.0/100 [01:33<05:41, 4.38s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  23%|██▎       | 23.0/100 [01:38<05:37, 4.38s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  24%|██▍       | 24.0/100 [01:42<05:38, 4.46s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  25%|██▌       | 25.0/100 [01:47<05:38, 4.52s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  26%|██▌       | 26.0/100 [01:52<05:44, 4.66s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  27%|██▋       | 27.0/100 [01:57<05:43, 4.71s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  28%|██▊       | 28.0/100 [02:02<05:36, 4.68s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  29%|██▉       | 29.0/100 [02:06<05:31, 4.68s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  30%|███       | 30.0/100 [02:11<05:26, 4.66s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  31%|███       | 31.0/100 [02:16<05:23, 4.69s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  32%|███▏      | 32.0/100 [02:20<05:22, 4.74s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  33%|███▎      | 33.0/100 [02:26<05:30, 4.93s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  34%|███▍      | 34.0/100 [02:31<05:33, 5.05s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  35%|███▌      | 35.0/100 [02:36<05:30, 5.08s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  36%|███▌      | 36.0/100 [02:41<05:22, 5.05s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  37%|███▋      | 37.0/100 [02:47<05:27, 5.20s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  38%|███▊      | 38.0/100 [02:52<05:26, 5.27s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  39%|███▉      | 39.0/100 [02:58<05:23, 5.31s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  40%|████      | 40.0/100 [03:03<05:24, 5.41s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  41%|████      | 41.0/100 [03:09<05:22, 5.47s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  42%|████▏     | 42.0/100 [03:14<05:18, 5.50s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  43%|████▎     | 43.0/100 [03:20<05:13, 5.50s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  44%|████▍     | 44.0/100 [03:26<05:17, 5.68s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  45%|████▌     | 45.0/100 [03:32<05:20, 5.84s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  46%|████▌     | 46.0/100 [03:37<05:02, 5.60s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  47%|████▋     | 47.0/100 [03:43<05:00, 5.68s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  48%|████▊     | 48.0/100 [03:49<04:51, 5.61s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  49%|████▉     | 49.0/100 [03:54<04:42, 5.55s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  50%|█████     | 50.0/100 [03:59<04:32, 5.44s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  51%|█████     | 51.0/100 [04:05<04:26, 5.45s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  52%|█████▏    | 52.0/100 [04:10<04:23, 5.49s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  53%|█████▎    | 53.0/100 [04:17<04:32, 5.79s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  54%|█████▍    | 54.0/100 [04:23<04:30, 5.88s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  55%|█████▌    | 55.0/100 [04:29<04:24, 5.87s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  56%|█████▌    | 56.0/100 [04:35<04:28, 6.09s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  57%|█████▋    | 57.0/100 [04:41<04:16, 5.97s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selecting Features:  58%|█████▊    | 58.0/100 [04:46<03:58, 5.69s/ features]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# Obtenemos qué features sfs nos ha seleccionado\n",
    "p_sfs = sfs(Xtrain_cleaned, Ytrain_sfs, 100, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevamente modificamos nuestro dataset para solo considerar las features dadas por el selector\n",
    "\n",
    "Xtrain_sfs = np.array([[x[i] for i in p_sfs] for x in Xtrain_cleaned])\n",
    "Xtest_sfs = np.array([[x[i] for i in p_sfs] for x in Xtest_cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el clasificador con k=1\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(Xtrain_sfs, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Calculamos el accuracy usando la función performance entregada en pybalu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos y vemos el resultado\n",
    "pred = knn.predict(Xtest_sfs)\n",
    "print(f\"Predicción tuvo un accuracy de {performance(pred, Ytest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Al igual que en la parte 1, usamos un $hdiv = 2$ y $vdiv = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'faces_ARLQ'\n",
    "\n",
    "LBPs2 = []\n",
    "IDs2 = []\n",
    "NNs2 = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    \n",
    "    if filename.endswith(\".png\"):\n",
    "        \n",
    "        # Para un archivo \"face_xxx_nn.png\", ID es xxx y nn es nn, ambos en int\n",
    "        id_nn = filename[:-4].split(\"_\")\n",
    "        ID = int(id_nn[1])\n",
    "        nn = int(id_nn[2])\n",
    "                \n",
    "        if ID % 2 == 0: # Nos quedamos con los pares\n",
    "            if nn <= 7: # y solo los 7 primeros\n",
    "                i += 1\n",
    "                      \n",
    "                # Leemos la imágen y obtenemos sus features dadas por lbp\n",
    "                im = imread(f\"{directory}/{filename}\")\n",
    "                lbp = lbp_features(im, hdiv=hdiv, vdiv=vdiv)\n",
    "               \n",
    "                # Guardamos los resultados\n",
    "                LBPs2.append(lbp)\n",
    "                IDs2.append(ID)\n",
    "                NNs2.append(nn)\n",
    "                \n",
    "                if i % 10 == 0:                    \n",
    "                    progressBar(i, 350, bar_length=20)\n",
    "print(f\"\\nLBPs Calculado\\nLBP Shape: {len(LBPs)}, {len(LBPs[0])}\\nIDs Shape: {len(IDs)}, 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain2, Xtest2, Ytrain2, Ytest2 = [], [], [], []\n",
    "\n",
    "# Como nos pide el enunciado, usamos las imágenes con nn=1 como testing, y el resto como training\n",
    "for lbp, ID, nn in zip(LBPs2, IDs2, NNs2):\n",
    "    if nn == 1:\n",
    "        Xtest2.append(lbp)\n",
    "        Ytest2.append(ID)\n",
    "    else:\n",
    "        Xtrain2.append(lbp)\n",
    "        Ytrain2.append(ID)\n",
    "\n",
    "# Transformamos a numpy arrays para que sea más fácil de trabajar (pybalu lo pide)\n",
    "Xtrain2 = np.array(Xtrain2)\n",
    "Ytrain2 = np.array(Ytrain2)\n",
    "Xtest2 = np.array(Xtest2)\n",
    "Ytest2 = np.array(Ytest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener las mismas features del clean de la parte 1, usamos el p_clean (en vez de calcular uno nuevo)\n",
    "Xtrain2_cleaned = np.array([[x[i] for i in p_clean] for x in Xtrain2])\n",
    "Xtest2_cleaned = np.array([[x[i] for i in p_clean] for x in Xtest2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Así, usamos p_sfs de la parte 1 para obtener las mismas features\n",
    "Xtrain2_sfs = np.array([[x[i] for i in p_sfs] for x in Xtrain2_cleaned])\n",
    "Xtest2_sfs = np.array([[x[i] for i in p_sfs] for x in Xtest2_cleaned])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos otra vez el clasificador con k=1\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn2.fit(Xtrain2_sfs, Ytrain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevamente predecimos y vemos el resultado\n",
    "\n",
    "pred2 = knn2.predict(Xtest2_sfs)\n",
    "print(f\"Predicción tuvo un accuracy de {performance(pred2, Ytest2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los ndarray nos son JSON serializable, por lo que los pasamos a una lista de ints\n",
    "\n",
    "p_clean_l = [int(p) for p in p_clean]\n",
    "p_sfs_l = [int(p) for p in p_sfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos lo necesario para que el proceso no se tenga que ejecutar nuevamente\n",
    "\n",
    "data = {}  \n",
    "data['hdiv'] = hdiv  \n",
    "data['vdiv'] = vdiv  \n",
    "data['p_clean'] = p_clean_l\n",
    "data['p_sfs'] = p_sfs_l\n",
    "\n",
    "with open('saved.txt', 'w') as out:  \n",
    "    json.dump(data, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de querer correr el modelo nuevamente, se usaría esta función.\n",
    "# Notamos que knn es un algoritmo 'lazy', por lo que requiere el Xtrain y Ytrain.\n",
    "# Si se prefiere pasar el modelo ya fiteado se da la opción\n",
    "\n",
    "def predict_from_scratch(filepath, data_filename, Xtrain=None, Ytrain=None, knn=None):\n",
    "    \n",
    "    if Xtrain is None or Ytrain is None:\n",
    "        assert knn, \"Por favor dar el modelo, o bien los datos Xtrain y Ytrain\"\n",
    "    \n",
    "    # Obtenemos los valores guardados\n",
    "    with open(data_filename) as f:  \n",
    "        data = json.load(f)\n",
    "        \n",
    "    hdiv = int(data['hdiv'])\n",
    "    vdiv = int(data['vdiv'])\n",
    "    local_p_clean = np.array(data['p_clean'])\n",
    "    local_p_sfs = np.array(data['p_sfs'])\n",
    "    \n",
    "    # Calculamos las features\n",
    "    im = imread(filepath)\n",
    "    lbp = lbp_features(im, hdiv=hdiv, vdiv=vdiv)\n",
    "    \n",
    "    # Filtramos\n",
    "    lbp_clean = np.array([lbp[i] for i in local_p_clean])\n",
    "    lbp_sfs = np.array([lbp_clean[i] for i in local_p_sfs])\n",
    "    lbp_sfs = lbp_sfs.reshape(1, -1)\n",
    "    \n",
    "    if not knn:\n",
    "        knn = KNeighborsClassifier(n_neighbors=1)\n",
    "        knn.fit(Xtrain, Ytrain)\n",
    "        \n",
    "    local_pred = knn.predict(lbp_sfs)\n",
    "    print(f\"La predicción es: {local_pred}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo\n",
    "predict_from_scratch('faces_ARLQ/face_001_03.png', 'saved.txt', knn=knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
